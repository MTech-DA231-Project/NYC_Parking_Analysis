{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# NYC Parking Violation Data Analysis"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Downloading\n",
    "- Download CSV file only. Don't download CSV for excel (https://data.cityofnewyork.us/City-Government/Parking-Violations-Issued-Fiscal-Year-2022/pvqr-7yc4)\n",
    "- NY site has an option to visualize the data (https://data.cityofnewyork.us/d/kvfd-bves/visualization)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Columns Description\n",
    "\n",
    "| Source   Column Name    | Description/Comment                                  |\n",
    "|-------------------------|------------------------------------------------------|\n",
    "| SUMMONS-NUMBER          | UNIQUE IDENTIFIER OF SUMMONS                         |\n",
    "| PLATE ID                | REGISTERED PLATE   ID                                |\n",
    "| REGISTRATION   STATE    | STATE OF PLATE   REGISTRATION                        |\n",
    "| PLATE TYPE              | TYPE OF PLATE                                        |\n",
    "| ISSUE-DATE              | ISSUE DATE                                           |\n",
    "| VIOLATION-CODE          | TYPE OF   VIOLATION                                  |\n",
    "| SUMM-VEH-BODY           | VEHICLE BODY TYPE   WRITTEN ON SUMMONS (SEDAN, ETC.) |\n",
    "| SUMM-VEH-MAKE           | MAKE OF CAR WRITTEN   ON SUMMONS                     |\n",
    "| VIOLATION   PRECINCT    | PRECINCT OF   VIOLATION                              |\n",
    "| ISSUER   PRECINCT       | PRECINCT OF   ISSUANCE                               |\n",
    "| VEHICLE COLOR           | CAR COLOR WRITTEN ON   SUMMONS                       |\n",
    "| VIOLATION   DESCRIPTION | DESCRIPTION OF   VIOLATION                           |"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Plate Type\n",
    "\n",
    "Registration Class Codes for vehicles. 3 letters code\n",
    "\n",
    "Common Plate types are \n",
    "* Passenger Vehicles (PAS): standard issue plates\n",
    "* Commercial Vehicles (COM): Full-size vans and most pickups\n",
    "* Medallion (OMT): Taxis\n",
    "* Personalized Plates (SRF): cars, mini-vans, SUVs and some pick-ups registered as passenger class\n",
    "* Special Omnibus Rentals (OMS)\n",
    "\n",
    "https://dmv.ny.gov/registration/registration-class-codes\n",
    "\n",
    "### Violation Code\n",
    "Type of violation. Codes are from 1-99. Fines are charged based on this\n",
    "\n",
    "https://data.cityofnewyork.us/api/views/pvqr-7yc4/files/7875fa68-3a29-4825-9dfb-63ef30576f9e?download=true&filename=ParkingViolationCodes_January2020.xlsx\n",
    "\n",
    "### Vehicle Body Type\n",
    "\n",
    "Common Vehicle body types are \n",
    "* suburban(SUBN): Vehicle that can be used to carry passengers and cargo\n",
    "* four-door sedan (4DSD)\n",
    "* Van Truck (VAN\n",
    "* Delivery Truck (DELV)\n",
    "* Pick-up Truck (PICK)\n",
    "* two-door sedan (2DSD) \n",
    "* Sedan (SEDN)\n",
    "\n",
    "https://nysdmv.custhelp.com/app/answers/detail/a_id/491/kw/body%20type%20subn\n",
    "\n",
    "### Vehicle Make\n",
    "\n",
    "The DMV code for the make of a vehicle that appears on the registration. The DMV make code is the first 5 letters of the vehicleâ€™s make name. If the vehicle make is more than one word, the make code is the first 2 letters of the first two words with a slash in between\n",
    "\n",
    "Common Vehicle Makes are \n",
    "* Honda (HONDA)\n",
    "* Toyota (TOYOT)\n",
    "* Ford (FORD)\n",
    "* Nissan (NISSA)\n",
    "* Chevrolet (CHEVR)\n",
    "* mercedes benz (ME/BE)\n",
    "\n",
    "https://data.ny.gov/Transportation/Vehicle-Makes-and-Body-Types-Most-Popular-in-New-Y/3pxy-wy2i\n",
    "https://data.ny.gov/api/assets/83055271-29A6-4ED4-9374-E159F30DB5AE\n",
    "\n",
    "### Vehicle Colors\n",
    "\n",
    "Common colors are\n",
    "* Gray (GY)\n",
    "* White (WH)\n",
    "* Black (BK)\n",
    "* Blue (BL)\n",
    "* Red (RD)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Config"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "source": [
    "# Use Sample file for speedy execution\n",
    "sample_file = True\n",
    "sample_file_path = \"../data/sample-100000.csv\"\n",
    "\n",
    "# For faster execution. Some statements are skipped based on this check\n",
    "presenting = False\n",
    "\n",
    "# Specify the years for which we are reading the data from CSV\n",
    "years = [2017, 2018, 2019, 2020, 2021]\n",
    "\n",
    "# Schema Types. Only specify for the not-string type & NULL columns. Others  are considered as string\n",
    "schema_types = {\n",
    "  \"Summons Number\": {\"type\": \"long\", \"null\": False},\n",
    "  \"Issue Date\"    : {\"type\": \"date\" if sample_file else \"string\", \"null\": True}, \n",
    "  \"Violation Code\": {\"type\": \"integer\", \"null\": True},\n",
    "  \"Violation Precinct\": {\"type\": \"integer\", \"null\": True},\n",
    "  \"Issuer Precinct\": {\"type\": \"integer\", \"null\": True},\n",
    "}\n",
    "\n",
    "# Columns which are used in the analysis. Other columns are removed\n",
    "used_columns = [\"Summons Number\", \"Plate ID\", \"Registration State\", \"Plate Type\", \"Issue Date\", \"Violation Code\", \"Vehicle Body Type\", \"Vehicle Make\", \"Violation Precinct\", \"Issuer Precinct\", \"Violation Time\", \"Vehicle Color\", \"Violation Description\"]\n",
    "\n",
    "# All the columns which are there in the datset (Need to be in CSV file order)\n",
    "schema_columns = [\"Summons Number\", \"Plate ID\", \"Registration State\", \"Plate Type\", \"Issue Date\", \"Violation Code\", \"Vehicle Body Type\", \"Vehicle Make\", \"Issuing Agency\", \"Street Code1\", \"Street Code2\", \"Street Code3\", \"Vehicle Expiration Date\", \"Violation Location\", \"Violation Precinct\", \"Issuer Precinct\", \"Issuer Code\", \"Issuer Command\", \"Issuer Squad\", \"Violation Time\", \"Time First Observed\", \"Violation County\", \"Violation In Front Of Or Opposite\", \"House Number\", \"Street Name\", \"Intersecting Street\", \"Date First Observed\", \"Law Section\", \"Sub Division\", \"Violation Legal Code\", \"Days Parking In Effect    \", \"From Hours In Effect\", \"To Hours In Effect\", \"Vehicle Color\", \"Unregistered Vehicle?\", \"Vehicle Year\", \"Meter Number\", \"Feet From Curb\", \"Violation Post Code\", \"Violation Description\", \"No Standing or Stopping Violation\", \"Hydrant Violation\", \"Double Parking Violation\"] if not sample_file else [i.lower().replace(\" \", '_') for i in used_columns]\n",
    "\n",
    "# Specify the CSV files path\n",
    "csv_files = sample_file_path if sample_file else \"../data/*.csv\"\n",
    "\n",
    "# Generates the sample CSV \n",
    "if not sample_file:\n",
    "  sample_CSV_generate = True # Generate the sample CSV\n",
    "  sample_CSV_records = 100000 # No. of records to write into the sample CSV file\n",
    "  sample_CSV_path = f\"../data/sample-{sample_CSV_records}.csv\" # path to save\n",
    "  sample_seed = sample_CSV_records # Seed value so that we get same random records"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Pre-processing Functions\n",
    "\n",
    "- All years data has same 43 columns\n",
    "- We have **Fiscal year data (July 1 - June 30)**. That means one file contains data for 2 years\n",
    "- **Issue Date:** We have to remove all the records which are outside of above condition\n",
    "- **Violation Code:** Codes other than those between 1 and 99\n",
    "- **Registration state:** has 99 invalid state code *(Take care in the analysis part)*\n",
    "- **Plate Type:** has more than 3 letters code. We have to remove them *(Take care in the analysis part)*\n",
    "- **Violation Time:** There are some times without P & A *(Take care in the analysis part)*\n",
    "\n",
    "> https://github.com/djha1208/NYC-Parking-Tickets-An-Exploratory-Analysis/blob/master/NYC_ParkingTickets_CaseStudy1.ipynb\n",
    "\n",
    "> https://towardsdatascience.com/learn-python-data-analytics-by-example-ny-parking-violations-e1ce1847fa2\n",
    "\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Removing the columns which are not used in our analysis"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "source": [
    "def remove_unused_columns(df, used_columns):\n",
    "\n",
    "  # Not used columns\n",
    "  # \"Issuing Agency\", \"Street Code1\", \"Street Code2\", \"Street Code3\", \"Vehicle Expiration Date\", \"Violation Location\", \"Issuer Code\", \"Issuer Command\", \"Issuer Squad\", \"Time First Observed\", \"Violation County\", \"Violation In Front Of Or Opposite\", \"House Number\", \"Street Name\", \"Intersecting Street\", \"Date First Observed\", \"Law Section\", \"Sub Division\", \"Violation Legal Code\", \"Days Parking In Effect    \", \"From Hours In Effect\", \"To Hours In Effect\", \"Unregistered Vehicle?\", \"Vehicle Year\", \"Meter Number\", \"Feet From Curb\", \"Violation Post Code\", \"No Standing or Stopping Violation\", \"Hydrant Violation\", \"Double Parking Violation\"\n",
    "\n",
    "  all_columns = set(df.columns)\n",
    "  used_columns = set(used_columns)\n",
    "  unused_columns = all_columns - used_columns\n",
    "\n",
    "  df = df.drop(*unused_columns)\n",
    "\n",
    "  print(f'No. of Columns (before dropping columns) : {len(all_columns)}')\n",
    "  print(f'No. of Columns (after dropping columns) : {len(df.columns)}')\n",
    "  print(f'No. of Rows : {df.count()}')\n",
    "\n",
    "  return df"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Dropping Duplicate Rows"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "source": [
    "def drop_duplicates(df):\n",
    "\n",
    "  print(f'No. of Records (before dropping duplicates) : {df.count()}')\n",
    "\n",
    "  df = df.drop_duplicates()\n",
    "\n",
    "  print(f'No. of Records (after dropping duplicates) : {df.count()}')\n",
    "\n",
    "  return df"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Converting column names to lower case & replacing spaces with _"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "source": [
    "def santize_column_names(df):\n",
    "\n",
    "  print(f'Columns (before sanitizing column names) : {df.columns}')\n",
    "\n",
    "  ## Slow\n",
    "  # columns = [column.lower().replace(\" \", \"_\") for column in df.columns ]\n",
    "  # df = df.toDF(*columns)\n",
    "\n",
    "  df = df.select([col(c).alias(c.lower().replace(\" \", '_')) for c in df.columns])\n",
    "\n",
    "  print(f'Columns (after sanitizing column names) : {df.columns}')\n",
    "\n",
    "  return df"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Ensure all the values in in a column are unique"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "source": [
    "def assert_uniqueness(df, column_name):\n",
    "\n",
    "  all_rows      = df.select(column_name).count()\n",
    "  distinct_rows = df.select(column_name).distinct().count()\n",
    "\n",
    "  assert all_rows == distinct_rows\n",
    "\n",
    "  print(f\"All values in {column_name} column are unique\")\n",
    "\n",
    "  return True"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Converting issue date string type to Date type"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "source": [
    "def convert_to_date(df, column_name, format):\n",
    "\n",
    "  df = (\n",
    "        df\n",
    "        .withColumn(\n",
    "          column_name, \n",
    "          F.to_date(col(column_name), format)\n",
    "        )\n",
    "      )\n",
    "  \n",
    "  return df"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Removing the rows which are outside of the passed years"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "source": [
    "def remove_outside_years_data(df, years, column_name):\n",
    "\n",
    "  print(f'Distinct years in {column_name} (before removing) : {df.select(F.year(col(column_name))).distinct().show()}')\n",
    "\n",
    "  min_year = min(years)\n",
    "  max_year = max(years)\n",
    "\n",
    "  df = (\n",
    "        df\n",
    "        .select('*')\n",
    "        .where(\n",
    "          (F.year(col(column_name)) >= min_year) \n",
    "          & \n",
    "          (F.year(col(column_name)) <= max_year)\n",
    "        )\n",
    "      )\n",
    "\n",
    "  print(f'Distinct years in {column_name} (after removing) : {df.select(F.year(col(column_name))).distinct().show()}')\n",
    "\n",
    "  return df"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Removing violation codes other than those between 1 and 99"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "source": [
    "def remove_invalid_violation_code_data(df):\n",
    "  \n",
    "  print(f'Distinct violation codes (before removing) : {df.select(\"violation_code\").distinct().count()}')\n",
    "\n",
    "  df = (\n",
    "        df\n",
    "        .select('*')\n",
    "        .where((col(\"violation_code\") >= 1) & (col(\"violation_code\") <= 99))\n",
    "      )\n",
    "      \n",
    "  print(f'Distinct violation codes (before removing) : {df.select(\"violation_code\").distinct().count()}')\n",
    "\n",
    "  return df\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Creating Spark session"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "findspark.find()\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.functions import col # Frequently using this. hence imported separately \n",
    "\n",
    "spark = (\n",
    "          SparkSession\n",
    "            .builder\n",
    "            .master(\"local[4]\") # Using 4 cores\n",
    "            .appName(\"NY_Parking_violation\")\n",
    "            .config('spark.ui.port', '4050')\n",
    "            .getOrCreate()\n",
    "        )\n",
    "spark"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://172.28.167.231:4050\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.2.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[4]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>NY_Parking_violation</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f31786fc0d0>"
      ]
     },
     "metadata": {},
     "execution_count": 67
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "source": [
    "# spark.stop() #TODO: Use this at the end of th script"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Reading CSV files into DataFrame"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "source": [
    "def get_schema(schema_columns, schema_types):\n",
    "  schema = []\n",
    "  for col in schema_columns:\n",
    "    schema_str = f\"`{col}` \"\n",
    "    if col in schema_types:\n",
    "      schema_str += f\"{schema_types[col]['type']} \"\n",
    "      schema_str += \"NOT NULL\" if not schema_types[col]['null'] else \"\"\n",
    "    else:\n",
    "      schema_str += \"string\"\n",
    "    schema.append(schema_str)\n",
    "  \n",
    "  return ','.join(schema)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "source": [
    "# Reading the CSV into data frame\n",
    "\n",
    "# Better performance than infer Schema True\n",
    "NY_schema = get_schema(schema_columns, schema_types)\n",
    "\n",
    "org_df = spark.read.option(\"header\", True).schema(NY_schema).csv(csv_files)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "source": [
    "print(f'Shape : {(org_df.count(), len(org_df.columns))}')\n",
    "org_df.printSchema()\n",
    "org_df.show(2)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Shape : (4005415, 13)\n",
      "root\n",
      " |-- summons_number: string (nullable = true)\n",
      " |-- plate_id: string (nullable = true)\n",
      " |-- registration_state: string (nullable = true)\n",
      " |-- plate_type: string (nullable = true)\n",
      " |-- issue_date: string (nullable = true)\n",
      " |-- violation_code: string (nullable = true)\n",
      " |-- vehicle_body_type: string (nullable = true)\n",
      " |-- vehicle_make: string (nullable = true)\n",
      " |-- violation_precinct: string (nullable = true)\n",
      " |-- issuer_precinct: string (nullable = true)\n",
      " |-- violation_time: string (nullable = true)\n",
      " |-- vehicle_color: string (nullable = true)\n",
      " |-- violation_description: string (nullable = true)\n",
      "\n",
      "+--------------+--------+------------------+----------+----------+--------------+-----------------+------------+------------------+---------------+--------------+-------------+---------------------+\n",
      "|summons_number|plate_id|registration_state|plate_type|issue_date|violation_code|vehicle_body_type|vehicle_make|violation_precinct|issuer_precinct|violation_time|vehicle_color|violation_description|\n",
      "+--------------+--------+------------------+----------+----------+--------------+-----------------+------------+------------------+---------------+--------------+-------------+---------------------+\n",
      "|    5115732543| KJW1071|                NY|       PAS|2021-07-05|             7|             4DSD|       HYUND|                 0|              0|         0100A|           RD| FAILURE TO STOP A...|\n",
      "|    4017873870| CSF8422|                NY|       OMS|2021-06-23|             5|             SUBN|       INFIN|                 0|              0|         0100P|           GY|   BUS LANE VIOLATION|\n",
      "+--------------+--------+------------------+----------+----------+--------------+-----------------+------------+------------------+---------------+--------------+-------------+---------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "source": [
    "presenting and org_df.summary().show() # More execution time"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "metadata": {},
     "execution_count": 72
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Pre-processing"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "source": [
    "# No pre-processing while using Sample file\n",
    "df = org_df\n",
    "if not sample_file:\n",
    "  df = remove_unused_columns(df, used_columns)\n",
    "  df = drop_duplicates(df)\n",
    "  df = santize_column_names(df)\n",
    "  assert_uniqueness(df, column_name=\"summons_number\")\n",
    "  df = convert_to_date(df, column_name=\"issue_date\", format=\"MM/dd/yyyy\")\n",
    "  df = remove_outside_years_data(df, years, \"issue_date\")\n",
    "  df = remove_invalid_violation_code_data(df)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "source": [
    "if not sample_file:\n",
    "  total_records = df.count()\n",
    "  print(f'Shape : {(total_records, len(df.columns))}')\n",
    "  df.printSchema()\n",
    "  df.show(2)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "source": [
    "presenting and df.describe().show() # More execution time"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "metadata": {},
     "execution_count": 75
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Saving Sample "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "source": [
    "from pathlib import Path\n",
    "from shutil import rmtree\n",
    "\n",
    "def write_CSV(df, CSV_path):\n",
    "  \n",
    "  # Creates CSV in a folder. But memory efficient\n",
    "  df.coalesce(1).write.mode(\"overwrite\").csv(CSV_path, header=True) \n",
    "\n",
    "  # Moving file to data folder\n",
    "  f_path = list(Path(CSV_path).glob('*.csv'))[0]\n",
    "  Path(f_path).rename(CSV_path+'.tmp')\n",
    "  rmtree(CSV_path)\n",
    "  Path(CSV_path+'.tmp').rename(CSV_path)\n",
    "\n",
    "  # df.toPandas().to_csv(CSV_path, index=False)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "source": [
    "if (not sample_file and sample_CSV_generate):\n",
    "  fraction = (sample_CSV_records+10000)/total_records # Exact records are not coming. Hence increasing the fraction using 10k\n",
    "  sample_df = df.sample(fraction=fraction, seed=sample_seed).limit(sample_CSV_records)\n",
    "  print(sample_df.count())\n",
    "  write_CSV(df, sample_CSV_path)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.7",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.7 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "77b0c884bf9a8c123a3b4d947573202ae62508f6aa4f4128a2a251680436629f"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}